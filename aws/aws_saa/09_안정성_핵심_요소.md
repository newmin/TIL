# 09. 안정성 핵심 요소
#TIL/aws/SAA

---

## 소개

안정성(Reliability)은 복원성(resiliency)이라고도 하며, 애플리케이션에서 장애가 일어나는 것을 예방하거나, 장애 발생 시 신속히 복구하는 능력을 뜻한다.  

애플리케이션의 안정성은 가용성(availability)으로 계량화하며, 애플리케이션이 예상대로 작동하는 시간을 백분율로 나타낸 것이다.  

애플리케이션의 가용성 수준은 네트워킹, 컴퓨팅, 스토리지 등 인프라의 일부를 구성하는 AWS 리소스의 가용성에 의존한다.  
AWS에서 제공하는 서비스도 가용성이 100%일 수는 없다.  
완벽하게 장애 발생을 막을 수는 없지만, 장애 발생 시 어떤 계획하에 어떻게 대처하느냐에 따라 애플리케이션의 가용성은 크게 달라질 수 있다.  


## 가용성 계산

가용성이랑 안정성 기준을 측정 가능하도록 계량화한 성능 지표이며, 애플리케이션이 예상한 대로 작동하는 시간을 백분율로 나타낸 것이다.  

다음은 가용성 비율을 기준으로 한 해 동안 애플리케이션이 이용이 불가능할 수 있는 기간을 보여준다.  

- 99%
	- 3일 15시간 39분
- 99.9%
	- 8시간 45분
- 99.95%
	- 4시간 22분
- 99.99%
	- 52분
- 99.999%
	- 5분

가용성은 '나인(nine)'의 개수로 표현하는 경우가 많다.  
'투 나인'은 99%, '쓰리 나인'은 99.9%, 99.95%는 '쓰리 나인 파이브'로 표현한다.  


### 기존 애플리케이션과 클라우드 네이티브 애플리케이션의 가용성 차이

AWS 아키텍트는 애플리케이션의 설계 방식에 따라 안정성이 달라질 수 있다는 점을 알고 있어야 한다.  
클라우드에서 운영하는 애플리케이션의 안정성은 기존 방식과 클라우드 네이티브 방식으로 나눠서 생각해볼 수 있다.  

- 기존 애플리케이션
	- 하나의 EC2 인스턴스와 다중 가용 영역(AZ) RDS를 배포해서 기존 애플리케이션을 실행하는 경우, 애플리케이션의 가용성은 EC2 인스턴스의 가용성과 RDS 인스턴스의 가용성에 달려있으며, 이를 `강한 의존성(hard dependencies)`이라 한다.
	- 애플리케이션의 전체 가용성을 계산하려면 강한 의존성을 지닌 리소스의 가용성을 모두 곱하면 된다.
	- 가용성을 높이고자 구성 요소를 중복해서 배치할 수 있다.
	- 각 구성 요소의 가용성은 100%에서 인스턴스 장애율을 빼서 계산한다.
		- EC2 인스턴스의 가용성이 99.99%인 경우 2개 EC2 인스턴스의 가용성은 `100% - (0.01% X 0.01%) = 99.999999%` 이다.
- 클라우드 네이티브 애플리케이션
	- 클라우드 네이티브 애플리케이션은 AWS와 같이 특정 클라우드 플랫폼의 리소스만을 사용해서 작성된다.
	- Lambda를 사용한 서버리스 애플리케이션, EC2에서 객체를 S3에 저장하는 애플리케이션, DynamoDB 등
	- 하나의 EC2 인스턴스에서 데이터베이스 스토리지로 DynamoDB를 사용하는 경우, 가용성은 `99.99% X 99.99% = 99.98%`이다.
	- 더 높은 가용성이 필요한 경우, 2개의 인스턴스를 다른 AZ에서 각각 하나씩 실행하고, ALB를 사용해서 이 두 인스턴스에 트래픽을 분배한다.
	- 2개 리전을 사용하면 가용성을 더 높일 수 있다.
		- 한 리전 내 다른 가용 영역에 각각 하나씩 인스턴스를 배포하고 ALB로 트래픽을 분산하는 구성을 만든 뒤, 이 구성을 다른 리전에 복제한 다음 Route 53 가중치 기반 라우팅 정책으로 2개 리전에 트래픽을 분산한다.
		- `100% - (0.01% X 0.01% X 0.01% X 0.01%) = 99.99999999999999%` , 식스틴 나인이다.
- Lambda로 서버리스 애플리케이션 구현
	- Lambda에서 실행되는 서버리스 애플리케이션과 EC2 인스턴스에서 실행되는 실행 파일이 어떻게 다른지 알아야 한다.
	- Lambda 함수는 일시적인 작업을 수행하는 데 유용하지만, EC2 인스턴스와 같이 지속적인 작업을 수행하는 데는 적합하지 않다.
	- Lambda는 고가용성 분산 컴퓨팅 플랫폼에서 함수를 실행하므로, 장애 발생으로 중지 또는 종료될 수 있는 EC2에 비해 가용성이 높다.


### 할당량 파악

AWS는 특정 사용자가 실수에 의해서든 혹은 의도적이든 모든 리소스를 점유해서 다른 사용자의 서비스 사용을 막는 경우가 발생하지 않도록 할당량을 두고 있다.  
네트워크 처리량, 초당 S3 PUT 요청, 리전 당 인스턴스 수, 리전 당 탄력적 IP 주소 수 등과 같이 서비스마다 할당량은 다르며 할당량 증갈글 AWS에 요청하면 용량을 높일 수 있다.  

계정에 적용된 서비스 할당량은 AWS Trusted Advisor에서 확인할 수 있다.  


### 가용성 증가

가용성을 극대화하는 가장 좋은 방법은 장애를 피하는 것이다.  
큰 인스턴스 한 개를 실행하는 대신 여러 가용 영역에 작은 인스턴스 여러 개를 분산하면, 단일 인스턴스에 장애가 발생하거나 가용 영역 전체가 중단되더라도 애플리케이션을 사용하지 못하는 상황을 피할 수 있다.  

하나의 인스턴스에 장애가 생겼다는 말은 곧 장애가 있는 인스턴스에서 감당해야 하는 부하를 다른 인스턴스가 대신 처리해야 한다는 의미이다.  
따라서 인스턴스에 장애가 발생했을 때, 동일한 인스턴스를 신속하게 생성할 수 있어야 한다.  

많은 부하가 인스턴스에 몰리면 사용이 어려울 정도로 느려지거나 아예 정지하는 문제도 생길 수 있다.  
분산 시스템으로 구성하면 인스턴스를 추가하는 수평 확장 조정으로 리소스 용량을 늘릴 수 있다.  


## EC2 Auto Scaling

EC2 Auto Scaling 서비스는 애플리케이션 장애를 방지하고, 장애가 발생했을 때 복구할 수 있는 방법을 제공한다.  
Auto Scaling은 지정한 개수의 EC2 인스턴스를 자동으로 프로비저닝해서 시작한다.  
수요가 증가하면 더 많은 인스턴스를 동적으로 추가할 수 있고, 인스턴스가 종료되거나 장애가 생기면 Auto Scaling이 자동으로 인스턴스를 교체한다.  

Auto Scaling은 시작 구성 또는 시작 템플릿에서 인스턴스의 프로비저닝 및 시작 작업을 자동으로 구성하고, 인스턴스를 구성하는 기본 파라미터와 시작할 때 실행될 스크립트를 정의한다.  


### 시작 구성

시작 구성(Launch Configuration)은 인스턴스를 수동으로 생성할 때 사용하며, AMI, 인스턴스 유형, SSH 키 페어, 보안 그룹, 인스턴스 프로필, 블록 장치 연결, EBS 최적화 여부, 배치 테넌시, 사용자 데이터 등의 구성 파라미터를 지정한다.  
시작 구성은 인스턴스를 수동으로 프로비저닝할 때 입력하는 정보와 같은 내용을 담고 있는 형식 문서이다.  

시작 구성은 기존 EC2 인스턴스에서 만들 수 있고, Auto Scaling이 인스턴스에서 설정을 복사한 뒤, 필요에 따라 그 설정을 변경해서 만들 수 있으며, 아예 백지 상태에서 처음부터 만들 수도 있다.  

시작 구성은 Auto Scaling에서만 사용되므로, 인스턴스를 직접 시작할 때 시작 구성을 활용할 수 없다.  
시작 구성을 만들고 나면 수정할 수 없으므로, 설정의 일부 내용을 수정하려면 새롭게 시작 구성을 작성해야 한다.  


### 시작 템플릿

시작 템플릿(Launch Templates)은 인스턴스를 수동으로 프로비저닝할 때 입력하는 정보를 설정 작업에 사용한다는 점에서 시작 구성과 유사하지만, 기존의 시작 구성보다 다양한 용도로 활용할 수 있다.  
Auto Scaling에서는 물론, EC2 인스턴스를 하나씩 확장할 때나 스팟 집합을 만들 때도 사용할 수 있다.  

시작 템플릿을 생성하고 난 후 수정할 수 있으며, 기존 템플릿과 수정 템플릿을 버전 별로 보관한다.  
AWS에 모든 버전을 보관하고 있다가 필요에 따라 앞 버전과 뒤 버전의 템플릿을 선택해서 사용할 수 있다.  


### Auto Scaling 그룹

Auto Scaling 그룹은 Auto Scaling이 관리하는 EC2 인스턴스의 그룹이며, Auto Scaling 그룹을 만들 때는 미리 만들어 놓은 시작 구성이나 시작 템플릿을 지정한다.  
Auto Scaling이 프로비저닝하고 유지해야 하는 가동 인스턴스의 숫자도 지정하고, Auto Scaling 그룹의 최소 및 최대 숫자도 지정하며, 유지해야 할 인스턴스의 목표 숫자도 선택적으로 설정할 수 있다.  

- 최소
	- 정상 인스턴스 수가 최솟값보다 적어지지 않도록 한다.
	- 0으로 설정하면 Auto Scaling은 인스턴스를 만들지 않고 그룹 내에서 가동 중인 모든 인스턴스를 종료한다.
- 최대
	- 정상 인스턴스 수가 최댓값을 넘지 않도록 한다.
- 목표 용량
	- 최솟값과 최댓값 사이에서 선택하며 반드시 설정해야 하는 것은 아니다.
	- 목표 용량을 지정하지 않으면 Auto Scaling은 최소 인스턴스 수로 시작하고, 목표 용량을 지정하면 Auto Scaling은 지정된 용량을 유지하기 위해 인스턴스를 추가하거나 종료한다.
	- 웹 콘솔에서는 목표 용량을 그룹 크기라고도 표시하기도 한다.


### Application Load Balancer 대상 그룹 지정

Application Load Balancer를 사용해 Auto Scaling 그룹에 있는 인스턴스로 트래픽을 분산하려면 Auto Scaling 그룹을 만들 때 ALB 대상 그룹의 이름을 넣는다.  
그러면 Auto Scaling이 새 인스턴스를 만들 때마다 자동으로 인스턴스를 ALB 대상 그룹에 추가한다.  


### 애플리케이션 인스턴스 상태 검사

기본적으로 Auto Scaling은 EC2 상태 검사를 기반으로 인스턴스의 상태를 판정한다.  

ALB를 사용해 트래픽을 인스턴스로 라우팅할 때 로드 밸런서 대상 그룹에 상태 검사를 구성할 수 있다.  
대상 그룹 상태 검사는 200에서 499 범위의 HTTP 응답 코드를 검사한다.  

ALB 상태 검사에서 인스턴스가 비정상으로 확인되면 그 인스턴스로 사용자의 트래픽이 전달되지 않도록 하고, Auto Scaling은 해당 인스턴스를 제거하고 대체 인스턴스를 만들어서 로드 밸런서의 대상 그룹에 추가해 새 인스턴스로 트래픽이 전달되도록 한다.  


## Auto Scaling 옵션

Auto Scaling에는 수요에 맞게 인스턴스의 수를 확장하는 몇 가지 다른 방법이 있다.  


### 수동 조정

그룹을 생성한 후 언제든지 Auto Scaling에서 최솟값, 목푯값, 최댓값을 변경하면 즉시 조정이 이루어진다.  


### 동적 조정 정책

AWS 관리형 리소스는 탄력성을 지니므로, 부하가 증가하면 그 부하를 처리할 수 있도록 자동으로 확장한다.  
관리형 리소스에는 S3, 로드 밸런서, 인터넷 게이트웨이, NAT 게이트웨이 등이 있다.  
반면 관리형 리소스가 아닌 EC2 인스턴스의 경우에는 사용자에게 수요에 대응할 수 있는 충분한 성능을 유지해야 하는 책임이 있다.  

인스턴스 리소스(CPU 사용률, 메모리, 디스크 공간)가 부족하면 장애로 이어질 가능성이 커지므로, 부하가 특정 지점에 이르기 직전에 동적 조정 정책으로 더 많은 인스턴스를 자동으로 프로비저닝해서 인스턴스가 과부하되지 않도록 해야 한다.  
Auto Scaling은 그룹에 있는 모든 인스턴스에 대해 다음의 집계 지표를 생성한다.  

- CPU 사용률 집계
- 대상당 평균 요청 수
- 평균 수신 네트워크 바이트
- 평균 송신 네트워크 바이트

위 지표 외에도 지표 필터를 사용해 CloudWatch Logs에서 지표를 추출해서 사용할 수도 있다.  

동적 조정 정책은 CloudWatch 경보 모니터링으로 작동하며 경보가 발생할 때 목표 용량을 늘려서 확장 조정을 수행한다.  
동적 조정 정책에는 단순 조정, 단계 조정, 대상 추적 조정의 3가지 정책이 있다.  











































